---
title: "Feature Engineering"
output: html_document
date: "2025-11-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("settings.R")
df <- read.csv(file.path(path_intermediate, "train_imputed.csv"))
```

# 1. Lectura de Datos y Conversión Inicial

Key (0-11) y time_signature (0, 1, 3, 4, 5) son numéricas en el fichero, pero no tienen propiedades matemáticas. Las convertimos a factor, le decimos a R que son etiquetas nominales. audio_mode (0/1) también se beneficia de ser un factor para que el modelo lo trate como dos grupos distintos.

```{r}
# Lista de variables categóricas
vars_categoricas <- c("key", "time_signature", "audio_mode")

df <- df %>%
  mutate(across(all_of(vars_categoricas), ~ as.factor(.x)))

# Comprobamos
str(df)
```


# 2. Variables Categóricas (OHE)

Aplicamos OHE para variables nominales con más de dos niveles, ya que permite a los modelos matemáticos (Regresión, KNN) usarlas sin asumir una relación ordinal falsa.

```{r}
#install.packages("fastDummies")
library(fastDummies)

# Creamos las variables dummy. 
# audio_mode no es necesaria aquí, R la manejará como 0/1.
# Conservamos las originales con remove_selected_columns = FALSE
df <- dummy_cols(df, 
                 select_columns = c("key", "time_signature"),
                 remove_first_dummy = TRUE, # Para evitar multicolinealidad
                 remove_selected_columns = FALSE) # Conserva las originales
```

# 3. instrumentalness (Exceso de Ceros)
Dado que la mayoría de canciones no son instrumentales (mediana 0.00), el hecho de ser o no instrumental puede ser más predictivo que su valor exacto.

```{r}
# Usamos un umbral (ej. 0.1) para decidir si es instrumental
df <- df %>%
  mutate(es_instrumental = ifelse(instrumentalness > 0.1, 1, 0))

```

# 4. Variables con Asimetría Positiva

El logaritmo "comprime" la cola derecha de la distribución, acercando los outliers al resto de los datos. Usamos log1p (que calcula log(x + 1)) para manejar correctamente los valores 0.

```{r}
library(dplyr)
# Lista de variables con asimetría positiva
vars_pos_skew <- c("song_duration_ms", "acousticness", "liveness", 
                     "speechiness", "instrumentalness")

df <- df %>%
  mutate(across(all_of(vars_pos_skew), 
                ~ log1p(.x), 
                .names = "{.col}_log")) # <-- '.names' CREA NUEVAS COLUMNAS

```

# 5. Variable audio_valence (Plana/Uniforme)
Al ser la distribución tan plana, realizar una Discretización puede ayudar al modelo a encontrar puntos de corte claros.

```{r}
df <- df %>%
  mutate(valence_binned = cut(audio_valence,
                               breaks = c(0, 0.33, 0.66, 1.0),
                               labels = c("valence_baja", "valence_media", "valence_alta"),
                               include.lowest = TRUE))

# Ahora, aplicamos OHE a esta nueva variable categórica
df <- dummy_cols(df, 
                 select_columns = c("valence_binned"),
                 remove_first_dummy = TRUE, 
                 remove_selected_columns = FALSE) # Conserva la original
```


# 6. Escalado de Todas las Variables Numéricas

Asegura que todas las variables tengan la misma escala (media 0, std 1). Sin esto, por ejemplo tempo (rango >100) dominaría el cálculo de distancia sobre danceability (rango 1).

Este paso lo deberíamos repetir con las variables que probemos en cada modelo.

```{r}
# Identificamos TODAS las variables numéricas que irán al modelo
# Este caso incluye todas
vars_to_scale <- c("danceability", "energy", "tempo", "loudness", 
                     "song_duration_ms_log", "acousticness_log", "liveness_log", 
                     "speechiness_log", "instrumentalness_log")

# Estandariza (escala) y crea nuevas columnas
df <- df %>%
  mutate(across(all_of(vars_to_scale), 
                ~ as.vector(scale(.x)), 
                .names = "{.col}_scaled")) # CREA NUEVAS COLUMNAS
```

A continuación, cuando debamos crear el modelo, tenemos que buscar interacciones y escoger las variables que nos acerquen al mejor modelo.

```{r}
#Seleccionamos SOLO las columnas finales para el modelo KNN
df_knn <- df %>%
  select(
    # 1. La variable objetivo
    song_popularity, 
    
    # 2. Las variables numéricas ya escaladas
    ends_with("_scaled"),
    
    # 3. La nueva feature binaria
    es_instrumental,
    
    # 4. El 'audio_mode' original (que ya es 0/1 o factor)
    audio_mode,
    
    # 5. Todas las dummies (OHE) creadas
    starts_with("key_"),
    starts_with("time_signature_"),
    starts_with("valence_binned_")
  )

# Ahora, 'df_knn' está perfectamente limpio y listo para entrenar KNN
# sin redundancia de datos.
str(df_knn)
```

# 7. Guardar los resultados del feature engineering (df_knn) como csv
```{r}
write.csv(df_knn, file = file.path(path_intermediate, "train_feat_eng.csv"))
```




